# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mW60yGJFIghfVrY_ehNQ5bEssz2L2idq
"""

from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import img_to_array
from sklearn.cluster import KMeans
import pandas as pd
import numpy as np
from tqdm import tqdm
import os
import shutil

from sklearn import svm

import pickle

# Function to Extract features from the images
def image_feature(direc):
    model = InceptionV3(weights='imagenet', include_top=False)
    features = [];
    img_name = [];
    if os.path.isdir(direc):
      for files in tqdm(os.listdir(direc)):
          fname=direc+'/'+files
          img=image.load_img(fname,target_size=(224,224))
          x = img_to_array(img)
          x=np.expand_dims(x,axis=0)
          x=preprocess_input(x)
          feat=model.predict(x)
          feat=feat.flatten()
          features.append(feat)
          img_name.append(files)
      return features,img_name
    else:
      files=direc.split("/")[-1]
      fname=direc
      img=image.load_img(fname,target_size=(224,224))
      x = img_to_array(img)
      x=np.expand_dims(x,axis=0)
      x=preprocess_input(x)
      feat=model.predict(x)
      feat=feat.flatten()
      features.append(feat)
      img_name.append(files)
      return features,img_name

"""#### Training"""

dataset_path="/content/Docs"
n=len(dataset_path)

labels = [label for label in os.listdir(dataset_path)]
id2label = {v: k for v, k in enumerate(labels)}
label2id = {k: v for v, k in enumerate(labels)}
label2id

images = []
labels = []

for label_folder, _, file_names in os.walk(dataset_path):
  if label_folder != dataset_path:
    label = label_folder[n:]
    for _, _, image_names in os.walk(label_folder):
      relative_image_names = []
      for image_file in image_names:
        relative_image_names.append(dataset_path + "/" + label + "/" + image_file)
      images.extend(relative_image_names)
      labels.extend([label] * len (relative_image_names)) 

data = pd.DataFrame.from_dict({'image_path': images, 'label': labels})
data.head()

train_y=list(data["label"])

data.head()

train_x=[]
for i in tqdm(data.image_path):
  img_features,img_name=image_feature(str(i))
  train_x.append(img_features)

train_x_1=train_x

train_x_2=np.array(train_x_1)

train_x_2.shape

nsamples, nx, ny = train_x_2.shape
train_dataset = train_x_2.reshape((nsamples,nx*ny))

clf_svm_wv = svm.SVC(kernel='rbf')
clf_svm_wv.fit(train_dataset, train_y)





"""#### Testing"""

path="/content/Test_3_tables"
test_x=[]
img_name=[]
if os.path.isdir(direc):
  for files in tqdm(os.listdir(direc)):
  img_name.append(files)
  fname=direc+'/'+files
  img_features,im_name=image_feature(str(fname))
  test_x.append(img_features)
          
else:
  files=direc.split("/")[-1]
  fname=direc
  img_name.append(files)
  img_features,im_name=image_feature(str(fname))
  test_x.append(img_features)

os.listdir("/content/Train_3/1080-receipt.jpg")

img_name=[]
for i in tqdm(os.listdir(path)):
  img_name.append(i)

img_name

test_x_1=np.array(test_x)
nsamples, nx, ny = test_x_1.shape
test_dataset = test_x_1.reshape((nsamples,nx*ny))

test_y=clf_svm_wv.predict(test_dataset)

len(test_y)

clf_svm_wv.predict(test_dataset)

Test_df = pd.DataFrame(img_name,columns=['image'])

Test_df

Test_df["label"]=test_y

Test_df

pickle.dump(clf_svm_wv, open("save_svm_feature.pkl", "wb"))